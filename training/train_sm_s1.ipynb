{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b9f1afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ryan\\miniconda3\\envs\\unsloth\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ryan\\miniconda3\\envs\\unsloth\\Lib\\site-packages\\unsloth_zoo\\gradient_checkpointing.py:339: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\c10/cuda/CUDAAllocatorConfig.h:28.)\n",
      "  GPU_BUFFERS = tuple([torch.empty(2*256*2048, dtype = dtype, device = f\"{DEVICE_TYPE}:{i}\") for i in range(n_gpus)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.7.9: Fast Qwen2 patching. Transformers: 4.53.3.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4070 Laptop GPU. Num GPUs = 1. Max memory: 7.996 GB. Platform: Windows.\n",
      "O^O/ \\_/ \\    Torch: 2.7.1+cu128. CUDA: 8.9. CUDA Toolkit: 12.8. Triton: 3.3.1\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.31.post1. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastVisionModel\n",
    "import torch\n",
    "\n",
    "model, processor = FastVisionModel.from_pretrained(\n",
    "    \"unsloth/Qwen2.5-VL-3B-Instruct-unsloth-bnb-4bit\",\n",
    "    load_in_4bit=True,  # Use 4bit to reduce memory use. False for 16bit LoRA.\n",
    "    use_gradient_checkpointing=\"unsloth\",  # True or \"unsloth\" for long context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17a1a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ryan\\miniconda3\\envs\\unsloth\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ryan\\miniconda3\\envs\\unsloth\\Lib\\site-packages\\unsloth_zoo\\gradient_checkpointing.py:339: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\c10/cuda/CUDAAllocatorConfig.h:28.)\n",
      "  GPU_BUFFERS = tuple([torch.empty(2*256*2048, dtype = dtype, device = f\"{DEVICE_TYPE}:{i}\") for i in range(n_gpus)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.7.9: Fast Qwen2 patching. Transformers: 4.53.3.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4070 Laptop GPU. Num GPUs = 1. Max memory: 7.996 GB. Platform: Windows.\n",
      "O^O/ \\_/ \\    Torch: 2.7.1+cu128. CUDA: 8.9. CUDA Toolkit: 12.8. Triton: 3.3.1\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.31.post1. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastVisionModel\n",
    "import torch\n",
    "\n",
    "model, processor = FastVisionModel.from_pretrained(\n",
    "    \"unsloth/Qwen2.5-VL-3B-Instruct-unsloth-bnb-4bit\",\n",
    "    load_in_4bit=True,  # Use 4bit to reduce memory use. False for 16bit LoRA.\n",
    "    use_gradient_checkpointing=\"unsloth\",  # True or \"unsloth\" for long context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "440f224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastVisionModel.get_peft_model(\n",
    "    model,\n",
    "    finetune_vision_layers=True,  # False if not finetuning vision layers\n",
    "    finetune_language_layers=True,  # False if not finetuning language layers\n",
    "    finetune_attention_modules=True,  # False if not finetuning attention layers\n",
    "    finetune_mlp_modules=True,  # False if not finetuning MLP layers\n",
    "    r=16,  # The larger, the higher the accuracy, but might overfit\n",
    "    lora_alpha=16,  # Recommended alpha == r at least\n",
    "    lora_dropout=0,\n",
    "    bias=\"none\",\n",
    "    random_state=3407,\n",
    "    use_rslora=False,  # We support rank stabilized LoRA\n",
    "    loftq_config=None,  # And LoftQ\n",
    "    target_modules=\"all-linear\",  # Optional now! Can specify a list if needed\n",
    "    modules_to_save=[\n",
    "        \"lm_head\",\n",
    "        \"embed_tokens\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c0879c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ryan\\miniconda3\\envs\\unsloth\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "base_url = \"../data_generation/dataset_s1_sm_disk/\"\n",
    "dataset = load_dataset(\n",
    "    \"arrow\",\n",
    "    data_files={\n",
    "        \"train\": base_url + \"train/data-00000-of-00001.arrow\",\n",
    "        \"test\": base_url + \"test/data-00000-of-00001.arrow\"\n",
    "    },\n",
    "    split=\"train\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e8d0e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=512x512>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[6][\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0555619b",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"Identify the GoBilda part shown in this image without further elaboration.\"\n",
    "\n",
    "def conversation_template(sample):\n",
    "    conversation = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": instruction},\n",
    "                {\"type\": \"image\", \"image\": sample[\"image\"]},\n",
    "            ],\n",
    "        },\n",
    "        {\"role\": \"assistant\", \"content\": [{\"type\": \"text\", \"text\": sample[\"label\"]}]},\n",
    "    ]\n",
    "    return {\"messages\": conversation}\n",
    "\n",
    "converted_dataset = [conversation_template(sample) for sample in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b3775e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The part in the image is a \"Round Hole Cover Plate.\" This type of part is typically used to cover the round hole (drill) at the top of a round exhaust outlet or vent for noise reduction, ventilation or air pressure. It is commonly used in industrial exhaust systems.<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "FastVisionModel.for_inference(model)\n",
    "\n",
    "image = dataset[2][\"image\"]\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"type\": \"image\"}, {\"type\": \"text\", \"text\": instruction}],\n",
    "    }\n",
    "]\n",
    "input_text = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "inputs = processor(\n",
    "    image,\n",
    "    input_text,\n",
    "    add_special_tokens=False,\n",
    "    return_tensors=\"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "\n",
    "text_streamer = TextStreamer(processor, skip_prompt=True)\n",
    "result = model.generate(\n",
    "    **inputs,\n",
    "    streamer=text_streamer,\n",
    "    max_new_tokens=128,\n",
    "    use_cache=True,\n",
    "    temperature=1.0,\n",
    "    top_p=0.95,\n",
    "    top_k=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f9ad5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Model does not have a default image size - using 512\n"
     ]
    }
   ],
   "source": [
    "from unsloth.trainer import UnslothVisionDataCollator\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "\n",
    "FastVisionModel.for_training(model)  # Enable for training!\n",
    "torch._dynamo.config.cache_size_limit = 32\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=processor,\n",
    "    data_collator=UnslothVisionDataCollator(model, processor),  # Must use!\n",
    "    train_dataset=converted_dataset,\n",
    "    args=SFTConfig(\n",
    "        per_device_train_batch_size=1,\n",
    "        gradient_accumulation_steps=4,\n",
    "        warmup_steps=5,\n",
    "        # max_steps=30,\n",
    "        num_train_epochs = 5, # Set this instead of max_steps for full training runs\n",
    "        learning_rate=2e-4,\n",
    "        logging_steps=1,\n",
    "        optim=\"adamw_8bit\",\n",
    "        weight_decay=0.01,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        seed=3407,\n",
    "        output_dir=\"outputs\",\n",
    "        report_to=\"none\",  # For Weights and Biases\n",
    "\n",
    "        # You MUST put the below items for vision finetuning:\n",
    "        remove_unused_columns=False,\n",
    "        dataset_text_field=\"\",\n",
    "        dataset_kwargs={\"skip_prepare_dataset\": True},\n",
    "        max_seq_length=2048,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cff0ccf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = NVIDIA GeForce RTX 4070 Laptop GPU. Max memory = 7.996 GB.\n",
      "4.184 GB of memory reserved.\n"
     ]
    }
   ],
   "source": [
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fed038c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 96 | Num Epochs = 5 | Total steps = 120\n",
      "O^O/ \\_/ \\    Batch size per device = 1 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4\n",
      " \"-____-\"     Trainable parameters = 41,084,928 of 3,795,707,904 (1.08% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [120/120 06:16, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8.146800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8.223600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7.959400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6.784600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>5.625400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>4.438400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.736300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.250700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.719400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.291700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.893000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.496300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.141600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.715400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.492200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.306300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.184800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.112800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.066000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.065600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.050500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.076700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.033100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.041900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.044600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.049300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.041000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.043400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.038400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.038800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.051400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.040400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.048900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.034900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.038700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.033100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.042900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.030100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.042700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.023200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.032500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.035400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.047300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.043500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.036900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.034800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.030500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.027400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.047800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.027200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.037300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.017900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.026300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.015900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.029200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.020300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.015800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.018200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.037800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.033600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.028000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.013400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.014500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.052200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.024700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.013600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.036800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.030700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.035500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.033400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.030900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.041100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.050700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.020200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.030100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.030700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.023500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.033900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.021000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.031700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.022100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.021100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.021200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.032200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.029700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.020400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.018800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.029300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.017000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.025100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.018200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.019500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.029100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.013400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.024200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.018700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.026500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.028000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>0.020600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>0.008200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>0.009700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>0.016000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.017100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>0.026900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>0.011100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>0.007300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>0.011700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.018800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>0.008700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>0.015200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>0.009300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>0.016400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>0.008400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>0.018000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>0.011400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>0.024200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>0.019400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.004600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "97503719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404.4422 seconds used for training.\n",
      "6.74 minutes used for training.\n",
      "Peak reserved memory = 4.303 GB.\n",
      "Peak reserved memory for training = 0.119 GB.\n",
      "Peak reserved memory % of max memory = 53.814 %.\n",
      "Peak reserved memory for training % of max memory = 1.488 %.\n"
     ]
    }
   ],
   "source": [
    "# @title Show final memory and time stats\n",
    "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
    "used_percentage = round(used_memory / max_memory * 100, 3)\n",
    "lora_percentage = round(used_memory_for_lora / max_memory * 100, 3)\n",
    "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
    "print(\n",
    "    f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\"\n",
    ")\n",
    "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
    "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
    "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
    "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0bedb337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"fl_lora\")  # Local saving\n",
    "processor.save_pretrained(\"fl_lora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7540fa78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ryan\\miniconda3\\envs\\unsloth\\Lib\\site-packages\\unsloth_zoo\\gradient_checkpointing.py:339: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\c10/cuda/CUDAAllocatorConfig.h:28.)\n",
      "  GPU_BUFFERS = tuple([torch.empty(2*256*2048, dtype = dtype, device = f\"{DEVICE_TYPE}:{i}\") for i in range(n_gpus)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.7.9: Fast Qwen2 patching. Transformers: 4.53.3.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4070 Laptop GPU. Num GPUs = 1. Max memory: 7.996 GB. Platform: Windows.\n",
      "O^O/ \\_/ \\    Torch: 2.7.1+cu128. CUDA: 8.9. CUDA Toolkit: 12.8. Triton: 3.3.1\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.31.post1. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UChannel4H<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastVisionModel\n",
    "\n",
    "model, processor = FastVisionModel.from_pretrained(\n",
    "    model_name = \"fl_lora\", # YOUR MODEL YOU USED FOR TRAINING\n",
    "    load_in_4bit = True, # Set to False for 16bit LoRA\n",
    ")\n",
    "FastVisionModel.for_inference(model)\n",
    "\n",
    "image = dataset[6][\"image\"]\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"type\": \"image\"}, {\"type\": \"text\", \"text\": instruction}],\n",
    "    }\n",
    "]\n",
    "input_text = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "inputs = processor(\n",
    "    image,\n",
    "    input_text,\n",
    "    add_special_tokens=False,\n",
    "    return_tensors=\"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "\n",
    "text_streamer = TextStreamer(processor, skip_prompt=True)\n",
    "result = model.generate(\n",
    "    **inputs,\n",
    "    streamer=text_streamer,\n",
    "    max_new_tokens=128,\n",
    "    use_cache=True,\n",
    "    temperature=1.0,\n",
    "    top_p=0.95,\n",
    "    top_k=64\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
